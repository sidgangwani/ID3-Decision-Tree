{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1_Siddhant_Gangwani.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9Qqt6hvJYEx"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pprint\n",
        "eps = np.finfo(float).eps\n",
        "\n",
        "#Importing necessary packages"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGegniEAJe7m"
      },
      "source": [
        "#Class which helps us read our dataset from csv file and replace '?' with most common value for that atrribute\n",
        "\n",
        "class DataReader:\n",
        "  def __init__(self, url):\n",
        "    self.feature_set = []\n",
        "    self.data = []\n",
        "    self.list_of_most_common_value = []\n",
        "    self.set_of_lines = []\n",
        "\n",
        "    for i in range(22):\n",
        "      feature_value_counter = Counter()\n",
        "      self.feature_set.append(feature_value_counter)\n",
        "\n",
        "    r = requests.get( url, stream=True )\n",
        "\n",
        "    for line in r.iter_lines():\n",
        "      line = line.decode('utf-8')\n",
        "      self.set_of_lines.append(line)\n",
        "\n",
        "  def find_most_common_values(self):\n",
        "    \n",
        "    for line in self.set_of_lines:\n",
        "      line_values = line.split(',')\n",
        "      \n",
        "      if len(line_values) != 23: \n",
        "        continue\n",
        "      \n",
        "      y_label = line_values[0]\n",
        "      x_atributes = line_values[1:]\n",
        "      \n",
        "      for i in range(22):\n",
        "        attribute_val = x_atributes[i]\n",
        "        if attribute_val !='?':\n",
        "          self.feature_set[i][attribute_val]+=1\n",
        "\n",
        "    for f in self.feature_set:\n",
        "      most_frequent_value = f.most_common()[0][0]\n",
        "      self.list_of_most_common_value.append(most_frequent_value)\n",
        "    \n",
        "  def read(self):\n",
        "\n",
        "    self.find_most_common_values()\n",
        "    \n",
        "    for line in self.set_of_lines:\n",
        "      \n",
        "      line_values = line.split(',')\n",
        "      \n",
        "      if len(line_values) != 23: \n",
        "        continue\n",
        "\n",
        "      y_label = [line_values[0]]\n",
        "      x_atributes = line_values[1:]\n",
        "      \n",
        "      for i in range(22):\n",
        "        attribute_val = x_atributes[i]\n",
        "        most_common_attribute_value = self.list_of_most_common_value[i]\n",
        "        if attribute_val =='?':\n",
        "          x_atributes[i]=most_common_attribute_value\n",
        "      \n",
        "      updated_data = y_label + x_atributes\n",
        "      self.data.append(updated_data)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7WrzXQCJh6P"
      },
      "source": [
        "train_data_url = 'https://raw.githubusercontent.com/jeniyat/CSE-5521-SP21/master/HW/HW1/Data/train.csv'\n",
        "dr = DataReader(train_data_url)\n",
        "dr.read()\n",
        "\n",
        "#Using Panda to convert it into dataframe\n",
        "train_data_frame = pd.DataFrame(dr.data)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROKVR3mVJjQc"
      },
      "source": [
        "#Function to calculate overall entropy of the system for a particular dataframe\n",
        "\n",
        "def entropy(train_data_frame):\n",
        "    entropy=0\n",
        "    \n",
        "    #The decision_column which is the first column in our dataframe that contains information about edibility of a mushroom\n",
        "    decision_column=train_data_frame.keys()[0]\n",
        "\n",
        "    #Attribute Values for the decision column which are 'e' and 'p'\n",
        "    attribute_values = train_data_frame[decision_column].unique()\n",
        "\n",
        "    #Calculating entropy using given formula\n",
        "    for values in attribute_values:\n",
        "        entropy=entropy-(train_data_frame[decision_column].value_counts()[values]/len(train_data_frame[decision_column]))*np.log2(train_data_frame[decision_column].value_counts()[values]/len(train_data_frame[decision_column]))\n",
        "    return entropy"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnpQ88cOJlZO"
      },
      "source": [
        "#Calculate entropy of attributes in the give dataframe\n",
        "\n",
        "def entropy_attribute(data_frame,attribute):\n",
        "\n",
        "    #The decision_column which is the first column in our dataframe that contains information about edibility of a mushroom\n",
        "    decision_column= data_frame.keys()[0]\n",
        "\n",
        "    #Attribute Values for the decision column which are 'e' and 'p'\n",
        "    dc_values=data_frame[decision_column].unique()  \n",
        "\n",
        "    #Attribute Values for the given attribute column\n",
        "    values = data_frame[attribute].unique()\n",
        "\n",
        "    total_entropy = 0\n",
        "\n",
        "    #Calculating total entropy of the given attribute column \n",
        "    for value in values:\n",
        "        entropy = 0\n",
        "\n",
        "        #Calculating entropy for all the attribute values of the given attribute column\n",
        "        for dc_value in dc_values:\n",
        "                total_attribute_values=len(data_frame[attribute][data_frame[attribute]==value])\n",
        "                particular_attribute_value=len(data_frame[attribute][data_frame[attribute]==value][data_frame[decision_column]==dc_value])\n",
        "\n",
        "                probability_attribute=particular_attribute_value/(total_attribute_values+eps)\n",
        "                entropy = entropy-probability_attribute*np.log2(probability_attribute+eps)\n",
        "\n",
        "        probability_system=total_attribute_values/len(data_frame)\n",
        "        total_entropy =total_entropy-probability_system*entropy\n",
        "    return abs(total_entropy)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlIRh488JoeI"
      },
      "source": [
        "#Getting a subset of a root_node\n",
        "\n",
        "def subset(data_frame,node,value):\n",
        "\n",
        "    #Getting the dataframe of a particular attribute value of a particular node/attribute for a particular decision column value\n",
        "    subset=data_frame[value==data_frame[node]].reset_index(drop=True)\n",
        "    return subset\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFte8vh1Jqgy"
      },
      "source": [
        "#Creating our ID3 decision tree\n",
        "\n",
        "def ID3_tree(data_frame): \n",
        "\n",
        "  #The decision_column which is the first column in our dataframe that contains information about edibility of a mushroom\n",
        "  decision_column = data_frame.keys()[0] \n",
        "\n",
        "  #List which stores info gains of attributes and their attribute values\n",
        "  info_gain_values=[]\n",
        "\n",
        "  #Calculating info gain for a particular attribute\n",
        "  for attributes in data_frame.keys()[1:]:\n",
        "      info_gain_values.append(entropy(data_frame)-entropy_attribute(data_frame,attributes))\n",
        "\n",
        "  #Getting the index/attribute which has the max info gain with respect to its parent node and the decision column\n",
        "  node=data_frame.keys()[1:][np.argmax(info_gain_values)]\n",
        "\n",
        "  #Attribute Values for a particular attribute column\n",
        "  attribute_values = np.unique(data_frame[node])  \n",
        "\n",
        "  #Creating an ID3 node                \n",
        "  id3_tree={}\n",
        "  id3_tree[node] = {}\n",
        "\n",
        "  for value in attribute_values:\n",
        "\n",
        "      root_subset=subset(data_frame,node,value)\n",
        "      counts=entropy(root_subset)\n",
        "\n",
        "      #Checking if the node is homogeneous i.e. its entropy is 0\n",
        "      if counts==0:\n",
        "          id3_tree[node][value] = np.unique(root_subset[0])[0]                                                 \n",
        "      else:        \n",
        "          id3_tree[node][value] = ID3_tree(root_subset)\n",
        "                    \n",
        "  return id3_tree"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOZB1IF0Jspb"
      },
      "source": [
        "#Creating the ID3 decision tree from our training set data\n",
        "\n",
        "id3_tree = ID3_tree(train_data_frame)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuJMrWl3J1Ig"
      },
      "source": [
        "#Creating the prediction function that will predict the edibility of a mushroom from a particular test_data row\n",
        "\n",
        "def prediction(test_data_row,id3_tree):\n",
        "\n",
        "    #Getting the nodes of our tree\n",
        "    for nodes in id3_tree.keys(): \n",
        "        prediction_value = 0     \n",
        "\n",
        "        #Getting the attribute value of the attribute node present in our tree from the test_data row\n",
        "        value = test_data_row[nodes]\n",
        "        id3_tree = id3_tree[nodes][value]\n",
        "        \n",
        "        #Checking if the tree needs to be further traversed\n",
        "        if type(id3_tree) is dict:\n",
        "            prediction_value = prediction(test_data_row, id3_tree)\n",
        "        else:\n",
        "            prediction_value = id3_tree\n",
        "            break;                            \n",
        "        \n",
        "    return prediction_value"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AoBEB0YJ4Tp",
        "outputId": "e5c26738-74b0-4ec5-f67d-8b978d0e5f04"
      },
      "source": [
        "#Printing our ID3 Decision Tree\n",
        "\n",
        "pprint.pprint(id3_tree)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{5: {'a': 'e',\n",
            "     'c': 'p',\n",
            "     'f': 'p',\n",
            "     'l': 'e',\n",
            "     'm': 'p',\n",
            "     'n': {20: {'b': 'e',\n",
            "                'h': 'e',\n",
            "                'k': 'e',\n",
            "                'n': 'e',\n",
            "                'o': 'e',\n",
            "                'r': 'p',\n",
            "                'w': {22: {'d': {8: {'b': 'e', 'n': 'p'}},\n",
            "                           'g': 'e',\n",
            "                           'l': {3: {'c': 'e', 'n': 'e', 'w': 'p', 'y': 'p'}},\n",
            "                           'p': 'e',\n",
            "                           'w': 'e'}},\n",
            "                'y': 'e'}},\n",
            "     'p': 'p',\n",
            "     's': 'p',\n",
            "     'y': 'p'}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdJ6ptpvJ5fF",
        "outputId": "ccd09a10-25a8-4314-ca5f-804cb1ed3326"
      },
      "source": [
        "#Getting our test_data from test_data csv file\n",
        "\n",
        "test_data_url = 'https://raw.githubusercontent.com/jeniyat/CSE-5521-SP21/master/HW/HW1/Data/test.csv'\n",
        "test_data = DataReader(test_data_url)\n",
        "test_data.read()\n",
        "\n",
        "test_df = pd.DataFrame(test_data.data)\n",
        "\n",
        "#Decision Column of our test_dataset\n",
        "testY_label=test_df[0]\n",
        "\n",
        "#Getting the attributes of the mushroom in our test_dataset\n",
        "testX_label=test_df.drop(0,axis=1)\n",
        "\n",
        "counter=0\n",
        "\n",
        "#Calculating accuracy score of our decision tree\n",
        "for i in range(1623):\n",
        "  num=prediction(testX_label.iloc[i],id3_tree)\n",
        "  if(num==testY_label[i]):\n",
        "    counter=counter+1\n",
        "accuracy=counter/(len(testY_label)-1)\n",
        "\n",
        "print('%.2f'%accuracy)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.00\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}